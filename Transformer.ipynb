{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled13.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBGS9Fg3VK4-"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4T1TsHf_5mZ",
        "outputId": "48d8ac83-f326-4d89-c32c-398d08e0f07b"
      },
      "source": [
        "data_file = open(\"dataset.txt\", \"r\")\n",
        "lines = data_file.readlines()\n",
        "\n",
        "letter_to_idx = {}\n",
        "idx_to_letter = {}\n",
        "cnt = 0\n",
        "for i in range(10):\n",
        "    letter_to_idx[str(i)] = len(letter_to_idx)\n",
        "for line in lines:\n",
        "    if \"sin\" in line or \"cos\" in line or \"tan\" in line:\n",
        "        line = line.replace(\"sin\", \"!\")\n",
        "        line = line.replace(\"cos\", \"@\")\n",
        "        line = line.replace(\"tan\", \"#\")\n",
        "        cnt += 1\n",
        "    \n",
        "    for letter in line:\n",
        "        if letter.isalpha(): letter = \"$\"\n",
        "        if letter not in letter_to_idx:\n",
        "            letter_to_idx[letter] = len(letter_to_idx)\n",
        "letter_to_idx[\"SOS\"] = len(letter_to_idx); letter_to_idx[\"EOS\"] = len(letter_to_idx);\n",
        "for k,v in letter_to_idx.items():\n",
        "    idx_to_letter[v] = k\n",
        "random.shuffle(lines)\n",
        "train_lines = lines[: int(len(lines)*0.99) ]\n",
        "test_lines = lines[int(len(lines)*0.99): ]\n",
        "print(len(train_lines),len(test_lines))\n",
        "print(cnt)\n",
        "print(letter_to_idx)\n",
        "print(idx_to_letter)\n",
        "print(len(lines))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "990000 10000\n",
            "30095\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '(': 10, '-': 11, '*': 12, '$': 13, ')': 14, '=': 15, '\\n': 16, '+': 17, '@': 18, '#': 19, '!': 20, 'SOS': 21, 'EOS': 22}\n",
            "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '(', 11: '-', 12: '*', 13: '$', 14: ')', 15: '=', 16: '\\n', 17: '+', 18: '@', 19: '#', 20: '!', 21: 'SOS', 22: 'EOS'}\n",
            "1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxyCS3ff_9pF"
      },
      "source": [
        "def line_2_tokens(line):\n",
        "    tokens = [ letter_to_idx[letter] if not letter.isalpha() else letter_to_idx[\"$\"] for letter in line]\n",
        "    return tokens\n",
        "\n",
        "def tokens_2_lines(line):\n",
        "    tokens = [ idx_to_letter[letter] for letter in line]\n",
        "    return tokens"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjCH8VHSEFmI"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        trg_vocab_size,\n",
        "        src_pad_idx,\n",
        "        num_heads,\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        forward_expansion,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
        "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            num_heads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            forward_expansion,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_seq_length, N = src.shape\n",
        "        trg_seq_length, N = trg.shape\n",
        "\n",
        "        src_positions = (\n",
        "            torch.arange(0, src_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(src_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        trg_positions = (\n",
        "            torch.arange(0, trg_seq_length)\n",
        "            .unsqueeze(1)\n",
        "            .expand(trg_seq_length, N)\n",
        "            .to(self.device)\n",
        "        )\n",
        "\n",
        "        embed_src = self.dropout(\n",
        "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
        "        )\n",
        "        embed_trg = self.dropout(\n",
        "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
        "        )\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        out = self.transformer(\n",
        "            embed_src,\n",
        "            embed_trg,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=trg_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PorGWW3Di9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae099043-1f16-4f83-f9bd-021d301de783"
      },
      "source": [
        "embedding_size = 384\n",
        "src_vocab_size = len(letter_to_idx)\n",
        "trg_vocab_size = len(letter_to_idx)\n",
        "num_heads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 29 + 2 # SOS and EOS\n",
        "forward_expansion = 4\n",
        "src_pad_idx = letter_to_idx[\"=\"] #use \"=\" as padding\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    trg_vocab_size,\n",
        "    src_pad_idx,\n",
        "    num_heads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    forward_expansion,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ")\n",
        "model.to(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (src_word_embedding): Embedding(23, 384)\n",
              "  (src_position_embedding): Embedding(31, 384)\n",
              "  (trg_word_embedding): Embedding(23, 384)\n",
              "  (trg_position_embedding): Embedding(31, 384)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (1): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (2): TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): _LinearWithBias(in_features=384, out_features=384, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=384, out_features=4, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "          (linear2): Linear(in_features=4, out_features=384, bias=True)\n",
              "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.1, inplace=False)\n",
              "          (dropout2): Dropout(p=0.1, inplace=False)\n",
              "          (dropout3): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=384, out_features=23, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weN1iYmEMN09"
      },
      "source": [
        "\n",
        "learning_rate = 3e-4\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4ExbOkDNsN3"
      },
      "source": [
        "def evaluate():\n",
        "    token_correct = total_tokens = sentence_correct = total_sentence = 0\n",
        "    for i, line in enumerate(test_lines): #use \"=\" as EOS\n",
        "        left = line.split(\"=\")[0]; right = line.split(\"=\")[1]\n",
        "        left = [letter_to_idx[\"SOS\"]] + line_2_tokens(left) + [letter_to_idx[\"EOS\"]]\n",
        "        right = [letter_to_idx[\"SOS\"]] + line_2_tokens(right) + [letter_to_idx[\"EOS\"]]\n",
        "        left = torch.tensor(left).reshape(-1,1).to(device); right = torch.tensor(right).reshape(-1,1).to(device)\n",
        "        \n",
        "        outputs = model(left, right[:-1,:])\n",
        "        outputs = outputs.reshape(-1, outputs.shape[2])\n",
        "        preds = np.argmax(outputs.cpu().detach().numpy(), axis=-1)\n",
        "\n",
        "        ground_truth = right[1:].reshape(-1)\n",
        "\n",
        "        sentence_is_correct = True\n",
        "        for p,g in zip(preds,ground_truth):\n",
        "            if p == g: token_correct += 1\n",
        "            else: sentence_is_correct = False\n",
        "            total_tokens += 1\n",
        "        if sentence_is_correct: sentence_correct += 1\n",
        "        total_sentence += 1\n",
        "    return token_correct, total_tokens, sentence_correct, total_sentence"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZvrN0WZAEWo",
        "outputId": "287628a6-e113-432c-e335-f4c59c3e91b7"
      },
      "source": [
        "batch_size = 128\n",
        "one_batch_left = one_batch_right = []\n",
        "losses_batch = []\n",
        "for i, line in enumerate(train_lines): #use \"=\" as EOS\n",
        "    left = line.split(\"=\")[0]; right = line.split(\"=\")[1]\n",
        "    left = [letter_to_idx[\"SOS\"]] + line_2_tokens(left) + [letter_to_idx[\"EOS\"]]\n",
        "    right = [letter_to_idx[\"SOS\"]] + line_2_tokens(right) + [letter_to_idx[\"EOS\"]]\n",
        "    left = torch.tensor(left).reshape(-1,1).to(device); right = torch.tensor(right).reshape(-1,1).to(device)\n",
        "    \n",
        "    outputs = model(left, right[:-1,:])\n",
        "    outputs = outputs.reshape(-1, outputs.shape[2])\n",
        "    ground_truth = right[1:].reshape(-1)\n",
        "    test = np.argmax(outputs.cpu().detach().numpy(), axis=-1)\n",
        "    loss = criterion(outputs, ground_truth)\n",
        "    # loss /= batch_size\n",
        "    losses_batch.append(loss)\n",
        "    if len(losses_batch) == batch_size:\n",
        "        optimizer.zero_grad()\n",
        "        losses_to_backprop = sum(losses_batch)\n",
        "        losses_to_backprop.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        losses_batch = []\n",
        "    if i % 40000 == 0 and i != 0: \n",
        "        token_correct, total_tokens, sentence_correct, total_sentence = evaluate()\n",
        "        print(token_correct, total_tokens, token_correct/total_tokens, sentence_correct, total_sentence, sentence_correct/total_sentence)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "131704 163402 0.8060121663137538 1234 10000 0.1234\n",
            "142888 163402 0.8744568609931335 2318 10000 0.2318\n",
            "146891 163402 0.8989547251563629 3034 10000 0.3034\n",
            "148508 163402 0.9088505648645672 3456 10000 0.3456\n",
            "150126 163402 0.9187525244489052 3653 10000 0.3653\n",
            "151048 163402 0.924395050244183 3715 10000 0.3715\n",
            "152113 163402 0.9309127183265811 3888 10000 0.3888\n",
            "152723 163402 0.9346458427681423 3988 10000 0.3988\n",
            "153092 163402 0.9369040770614803 4058 10000 0.4058\n",
            "153646 163402 0.940294488439554 4155 10000 0.4155\n",
            "153976 163402 0.9423140475636773 4230 10000 0.423\n",
            "154224 163402 0.9438317768448367 4323 10000 0.4323\n",
            "154500 163402 0.9455208626577398 4417 10000 0.4417\n",
            "154894 163402 0.9479320938544203 4556 10000 0.4556\n",
            "155080 163402 0.9490703908152899 4578 10000 0.4578\n",
            "155188 163402 0.9497313374377303 4634 10000 0.4634\n",
            "155508 163402 0.9516896978005165 4704 10000 0.4704\n",
            "155456 163402 0.9513714642415637 4731 10000 0.4731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn9GW1O7Auk4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "1e3a33b4-91fa-4afa-98cb-b3d0a992859b"
      },
      "source": [
        "batch_size = 128\n",
        "one_batch_left = one_batch_right = []\n",
        "losses_batch = []\n",
        "for i, line in enumerate(train_lines): #use \"=\" as EOS\n",
        "    left = line.split(\"=\")[0]; right = line.split(\"=\")[1]\n",
        "    left = [letter_to_idx[\"SOS\"]] + line_2_tokens(left) + [letter_to_idx[\"EOS\"]]\n",
        "    right = [letter_to_idx[\"SOS\"]] + line_2_tokens(right) + [letter_to_idx[\"EOS\"]]\n",
        "    left = torch.tensor(left).reshape(-1,1).to(device); right = torch.tensor(right).reshape(-1,1).to(device)\n",
        "    \n",
        "    outputs = model(left, right[:-1,:])\n",
        "    outputs = outputs.reshape(-1, outputs.shape[2])\n",
        "    ground_truth = right[1:].reshape(-1)\n",
        "    test = np.argmax(outputs.cpu().detach().numpy(), axis=-1)\n",
        "    loss = criterion(outputs, ground_truth)\n",
        "    # loss /= batch_size\n",
        "    losses_batch.append(loss)\n",
        "    if len(losses_batch) == batch_size:\n",
        "        optimizer.zero_grad()\n",
        "        losses_to_backprop = sum(losses_batch)\n",
        "        losses_to_backprop.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        losses_batch = []\n",
        "    if i % 40000 == 0 and i != 0: \n",
        "        token_correct, total_tokens, sentence_correct, total_sentence = evaluate()\n",
        "        print(token_correct, total_tokens, token_correct/total_tokens, sentence_correct, total_sentence, sentence_correct/total_sentence)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cf33b5762d4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mone_batch_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_batch_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlosses_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#use \"=\" as EOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mletter_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SOS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mline_2_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mletter_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EOS\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_lines' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usWqj9gg3rjz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Br4Vqa89fd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AH7jwQV89kS"
      },
      "source": [
        "src = torch.rand(3,2).long()\n",
        "trg = torch.rand(14,2).long()\n",
        "print(src,trg)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4yFxs8y89p1",
        "outputId": "7cd1de67-a041-4ce9-a407-8d6fbad5de39"
      },
      "source": [
        "output = model(src, trg[:-1, :])\n",
        "output = output.reshape(-1, output.shape[2])\n",
        "print(output.shape)\n",
        "target = trg[1:].reshape(-1)\n",
        "print(target.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([26, 20])\n",
            "torch.Size([26])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKKUTOrb3u9d",
        "outputId": "88babecd-3561-4167-bb22-087d61d61391"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters() ) #if p.requires_grad)\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4810027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8enExxs5BQN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}