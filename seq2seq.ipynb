{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYg6EbxiCql5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtoNOoSFC7BP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96ccd1d-d37a-4ffb-be7e-097417e10afa"
      },
      "source": [
        "data_file = open(\"dataset.txt\", \"r\")\n",
        "lines = data_file.readlines()\n",
        "\n",
        "def func_replacer(line):\n",
        "    line = line\n",
        "    if \"sin\" in line or \"cos\" in line or \"tan\" in line:\n",
        "        line = line.replace(\"sin\", \"!\")\n",
        "        line = line.replace(\"cos\", \"@\")\n",
        "        line = line.replace(\"tan\", \"#\")\n",
        "    return line\n",
        "\n",
        "letter_to_idx = {}\n",
        "idx_to_letter = {}\n",
        "cnt = 0\n",
        "for i in range(10):\n",
        "    letter_to_idx[str(i)] = len(letter_to_idx)\n",
        "for line in lines:\n",
        "    line = func_replacer(line)\n",
        "    for letter in line: \n",
        "        if letter.isalpha(): letter = \"$\";\n",
        "        if letter not in letter_to_idx and letter != \"=\": letter_to_idx[letter] = len(letter_to_idx);\n",
        "\n",
        "processed_lines = []\n",
        "max_digit = 0\n",
        "max_num = 0\n",
        "for line in lines:\n",
        "    line = func_replacer(line)\n",
        "    line = line.replace(\"\\n\", \"\")\n",
        "    left = line.split(\"=\")[0]\n",
        "    right = line.split(\"=\")[1]\n",
        "    processed_line_0 = []\n",
        "    processed_line_1 = []\n",
        "    for i, letter in enumerate(left):\n",
        "        processed_letter = None\n",
        "        if letter.isnumeric():\n",
        "            j = i+1; digit = 0\n",
        "            while j < len(left):\n",
        "                if left[j].isnumeric(): \n",
        "                    digit += 1\n",
        "                    if digit > max_digit: max_digit = digit\n",
        "                else: break\n",
        "                j += 1\n",
        "            processed_letter = str(int(letter)*(10**digit))\n",
        "            processed_line_0.append( processed_letter )\n",
        "        else: \n",
        "            processed_letter = letter\n",
        "            processed_line_0.append( processed_letter )\n",
        "        if processed_letter not in letter_to_idx and letter != \"=\": letter_to_idx[processed_letter] = len(letter_to_idx);\n",
        "\n",
        "    for i, letter in enumerate(right):\n",
        "        processed_letter = None\n",
        "        if letter.isnumeric():\n",
        "            j = i+1; digit = 0\n",
        "            while j < len(right):\n",
        "                if right[j].isnumeric(): \n",
        "                    digit += 1\n",
        "                    if digit > max_digit: max_digit = digit\n",
        "                else: break\n",
        "                j += 1\n",
        "            processed_letter = str(int(letter)*(10**digit))\n",
        "            processed_line_1.append( processed_letter )\n",
        "        else: \n",
        "            processed_letter = letter\n",
        "            processed_line_1.append( processed_letter )\n",
        "        if processed_letter not in letter_to_idx and letter != \"=\": letter_to_idx[processed_letter] = len(letter_to_idx);\n",
        "\n",
        "    processed_lines.append( (processed_line_0,processed_line_1))\n",
        "\n",
        "for k,v in letter_to_idx.items(): idx_to_letter[v] = k\n",
        "\n",
        "random.shuffle(processed_lines)\n",
        "train_lines = processed_lines[: int(len(lines)*0.99) ]\n",
        "test_lines = processed_lines[int(len(lines)*0.99): ]\n",
        "print(len(train_lines),len(test_lines))\n",
        "print(cnt)\n",
        "print(letter_to_idx)\n",
        "print(idx_to_letter)\n",
        "print(len(lines))\n",
        "idx_to_letter[52] = \"START\"; idx_to_letter[53] = \"END\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "990000 10000\n",
            "0\n",
            "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9, '(': 10, '-': 11, '*': 12, '$': 13, ')': 14, '\\n': 15, '+': 16, '@': 17, '#': 18, '!': 19, 'z': 20, '10': 21, '60': 22, 's': 23, 'n': 24, 'x': 25, '20': 26, '90': 27, 'c': 28, '100': 29, 'k': 30, '200': 31, '40': 32, 'j': 33, 'h': 34, '50': 35, 'y': 36, '30': 37, '300': 38, '80': 39, 'i': 40, 'o': 41, '400': 42, 'a': 43, '700': 44, '600': 45, '70': 46, 't': 47, '900': 48, '500': 49, '800': 50, '1000': 51}\n",
            "{0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9', 10: '(', 11: '-', 12: '*', 13: '$', 14: ')', 15: '\\n', 16: '+', 17: '@', 18: '#', 19: '!', 20: 'z', 21: '10', 22: '60', 23: 's', 24: 'n', 25: 'x', 26: '20', 27: '90', 28: 'c', 29: '100', 30: 'k', 31: '200', 32: '40', 33: 'j', 34: 'h', 35: '50', 36: 'y', 37: '30', 38: '300', 39: '80', 40: 'i', 41: 'o', 42: '400', 43: 'a', 44: '700', 45: '600', 46: '70', 47: 't', 48: '900', 49: '500', 50: '800', 51: '1000'}\n",
            "1000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8JU7C_Zdaj-",
        "outputId": "0760d663-6bed-40ec-bf82-352498e07fa4"
      },
      "source": [
        "# test = tensor_preparer(['(-2*@(n)-6)*(7*@(n)+13)=-14*@(n)**2-68*@(n)-78\\n'])[0][0].view(-1).cpu().detach().numpy()\n",
        "# print(test)\n",
        "# tokens_2_lines(test)\n",
        "# print(test_lines[:1000])\n",
        "print(letter_to_idx.keys())\n",
        "print(len(letter_to_idx))\n",
        "print(test_lines[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '(', '-', '*', '$', ')', '\\n', '+', '@', '#', '!', 'z', '10', '60', 's', 'n', 'x', '20', '90', 'c', '100', 'k', '200', '40', 'j', 'h', '50', 'y', '30', '300', '80', 'i', 'o', '400', 'a', '700', '600', '70', 't', '900', '500', '800', '1000'])\n",
            "52\n",
            "(['-', '9', '*', 'i', '*', '(', 'i', '+', '10', '3', ')'], ['-', '9', '*', 'i', '*', '*', '2', '-', '100', '10', '7', '*', 'i'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axKZ7L8tEAYW"
      },
      "source": [
        "\n",
        "device = torch.device(\"cuda\")\n",
        "def line_2_tokens(line):\n",
        "    tokens = [ letter_to_idx[letter] if not letter.isalpha() else letter_to_idx[\"$\"] for letter in line]\n",
        "    return tokens\n",
        "\n",
        "def tokens_2_lines(line):\n",
        "    tokens = [ idx_to_letter[letter] for letter in line]\n",
        "    return tokens\n",
        "def tensor_preparer(lines):\n",
        "    tensor_lines = []\n",
        "    for line in lines:\n",
        "        encoder_tokens = torch.tensor( line_2_tokens( line[0] ) ).view(-1,1).to(device)\n",
        "        decoder_tokens = torch.tensor( line_2_tokens( line[1] ) + [len(letter_to_idx)+1] ).view(-1,1).to(device)\n",
        "        tensor_lines.append((encoder_tokens, decoder_tokens))\n",
        "    return tensor_lines"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LcO5q1-ELh7"
      },
      "source": [
        "train_tensors = tensor_preparer(train_lines)\n",
        "test_tensors = tensor_preparer(test_lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3wlvfckEy4n"
      },
      "source": [
        "MAX_LENGTH = 29\n",
        "SOS_token = len(letter_to_idx)\n",
        "EOS_token = len(letter_to_idx) + 1\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=3)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(3, 1, self.hidden_size, device=device)\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, num_layers=3)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(3, 1, self.hidden_size, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBVpvsZXE6DH"
      },
      "source": [
        "hidden_size = 256\n",
        "vocab_size = len(letter_to_idx)\n",
        "encoder = EncoderRNN(vocab_size, hidden_size).to(device)\n",
        "attn_decoder = AttnDecoderRNN(hidden_size, vocab_size + 2, dropout_p=0.1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL_6l8FTJ7BE"
      },
      "source": [
        "learning_rate = 0.01\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.SGD(attn_decoder.parameters(), lr=learning_rate)\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFPJu3qNKQTK"
      },
      "source": [
        "def evaluate(encoder, decoder, max_length=MAX_LENGTH):\n",
        "    total_instances = instance_correct = token_correct = total_token = 0;\n",
        "    with torch.no_grad():\n",
        "        for i, pair in enumerate(test_tensors):\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "            input_tensor = pair[0]\n",
        "            target_tensor = pair[1]\n",
        "            input_length = input_tensor.size(0)\n",
        "            target_length = target_tensor.size(0)\n",
        "            encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "            loss = 0\n",
        "\n",
        "            for ei in range(input_length):\n",
        "                encoder_output, encoder_hidden = encoder(\n",
        "                    input_tensor[ei], encoder_hidden)\n",
        "                encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "            decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            loss = 0\n",
        "\n",
        "            preds = []\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                    decoder_input, decoder_hidden, encoder_outputs)\n",
        "                pred = np.argmax(decoder_output.cpu().detach().numpy(), axis=-1)[0]\n",
        "                preds.append(pred)\n",
        "                loss += criterion(decoder_output, target_tensor[di])\n",
        "                decoder_input = target_tensor[di]\n",
        "                # if decoder_input.item() == EOS_token:\n",
        "                #     break\n",
        "            # print(tokens_2_lines(preds))\n",
        "            # print(tokens_2_lines(target_tensor.view(-1).cpu().detach().numpy()))\n",
        "            # print(\" \")\n",
        "            sentence_correct = True\n",
        "            for p, t in zip(preds, target_tensor.view(-1).cpu().detach().numpy()):\n",
        "                if p == t: token_correct += 1\n",
        "                else: sentence_correct = False\n",
        "                total_token += 1\n",
        "            if sentence_correct: instance_correct += 1\n",
        "            total_instances += 1\n",
        "\n",
        "    return total_instances, instance_correct, token_correct, total_token\n",
        "\n",
        "\n",
        "def train(encoder, decoder, epoches=1):\n",
        "    start = time.time()\n",
        "    for i, pair in enumerate(train_tensors):\n",
        "\n",
        "        input_tensor = pair[0]\n",
        "        target_tensor = pair[1]\n",
        "\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        input_length = input_tensor.size(0)\n",
        "        target_length = target_tensor.size(0)\n",
        "        encoder_outputs = torch.zeros(MAX_LENGTH, encoder.hidden_size, device=device)\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(\n",
        "                input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "        \n",
        "        loss = 0\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        if i % 20000 == 0: \n",
        "            end = time.time()\n",
        "            print(end-start, end = \" \")\n",
        "            start = end\n",
        "            print(i/len(train_lines), end =\" \")\n",
        "        if i % 60000 == 0 and i != 0:\n",
        "            total_instances, instance_correct, token_correct, total_token = evaluate(encoder, attn_decoder)\n",
        "            print(\" \")\n",
        "            print(token_correct, total_token, token_correct/total_token, instance_correct, total_instances, instance_correct/total_instances)\n",
        "            print(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZhnZExDMNIn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "2ada5347-a325-4e9a-e7c8-af507089606e"
      },
      "source": [
        "train(encoder, attn_decoder)\n",
        "# evaluate(encoder, attn_decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0854482650756836 0.0 808.4351253509521 0.020202020202020204 807.0373070240021 0.04040404040404041 793.9648885726929 0.06060606060606061  \n",
            "136996 153098 0.89482553658441 2794 10000 0.2794\n",
            " \n",
            "936.5924754142761 0.08080808080808081 790.5000705718994 0.10101010101010101 798.5208611488342 0.12121212121212122  \n",
            "142831 153098 0.9329383793387243 4030 10000 0.403\n",
            " \n",
            "949.6776471138 0.1414141414141414 823.286376953125 0.16161616161616163 827.2908527851105 0.18181818181818182  \n",
            "144454 153098 0.9435394322590759 4330 10000 0.433\n",
            " \n",
            "963.3850231170654 0.20202020202020202 808.0658020973206 0.2222222222222222 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3ac546eefbab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# evaluate(encoder, attn_decoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-b932217e9d46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(encoder, decoder, epoches)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "socLHnCZathL"
      },
      "source": [
        "total_instances, instance_correct, token_correct, total_token = evaluate(encoder, attn_decoder)\n",
        "print(token_correct, total_token, token_correct/total_token, instance_correct, total_instances, instance_correct/total_instances)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU-VyTMNMRT5"
      },
      "source": [
        "evaluate(encoder, attn_decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2O5oEgVcp3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e8acf47-6b48-4070-95c5-3d1393eada53"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in encoder.parameters() ) #if p.requires_grad)\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "802816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKRwzb8wgmWO",
        "outputId": "8a06fa25-b184-47e1-80ea-492a1f7eb556"
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in attn_decoder.parameters() ) #if p.requires_grad)\n",
        "print(pytorch_total_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1358163\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5d6jMaWgoc6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}